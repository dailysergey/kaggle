{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occasional-aircraft",
   "metadata": {
    "papermill": {
     "duration": 0.019336,
     "end_time": "2021-05-10T10:03:46.146417",
     "exception": false,
     "start_time": "2021-05-10T10:03:46.127081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Version changes:\n",
    "* use eca-nfnet-l1 more powerful\n",
    "* use 4 model for iamges [ eca-nfnet-l0, eca-nfnet-l1, efficientnet_b3, efnet-b5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optional-cuisine",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:46.188295Z",
     "iopub.status.busy": "2021-05-10T10:03:46.187797Z",
     "iopub.status.idle": "2021-05-10T10:03:46.191964Z",
     "shell.execute_reply": "2021-05-10T10:03:46.191386Z"
    },
    "papermill": {
     "duration": 0.027052,
     "end_time": "2021-05-10T10:03:46.192084",
     "exception": false,
     "start_time": "2021-05-10T10:03:46.165032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:46.234706Z",
     "iopub.status.busy": "2021-05-10T10:03:46.234116Z",
     "iopub.status.idle": "2021-05-10T10:03:55.459844Z",
     "shell.execute_reply": "2021-05-10T10:03:55.458870Z"
    },
    "papermill": {
     "duration": 9.249682,
     "end_time": "2021-05-10T10:03:55.459992",
     "exception": false,
     "start_time": "2021-05-10T10:03:46.210310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import math\n",
    "import random \n",
    "import os \n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import transformers\n",
    "from transformers import (BertTokenizer, BertModel,DistilBertTokenizer, DistilBertModel)\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import gc\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "# how to make predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "architectural-chicken",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:55.503033Z",
     "iopub.status.busy": "2021-05-10T10:03:55.502323Z",
     "iopub.status.idle": "2021-05-10T10:03:55.504750Z",
     "shell.execute_reply": "2021-05-10T10:03:55.505194Z"
    },
    "papermill": {
     "duration": 0.026462,
     "end_time": "2021-05-10T10:03:55.505321",
     "exception": false,
     "start_time": "2021-05-10T10:03:55.478859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    img_size = 512\n",
    "    batch_size = 12\n",
    "    seed = 2021\n",
    "\n",
    "    bert_hidden_size = 768\n",
    "    \n",
    "    device = 'cuda'\n",
    "    classes = 11014\n",
    "    \n",
    "    model_name1 = 'eca_nfnet_l1'\n",
    "    model_path1 = '../input/effb-shopee/arcface_512x512_nfnet_l0(mish)_ep15.pt'\n",
    "    \n",
    "    model_name2 = 'efficientnet_b3'\n",
    "    model_path2 = '../input/shopee-pytorch-models/arcface_512x512_eff_b3.pt'\n",
    "    \n",
    "    model_name3 = 'tf_efficientnet_b5_ns'\n",
    "    model_path3 = '../input/shopee-pytorch-models/arcface_512x512_eff_b5_.pt'\n",
    "    \n",
    "    model_name4 = 'eca_nfnet_l0'\n",
    "    model_path4 = '../input/shopee-pytorch-models/arcface_512x512_nfnet_l0 (mish).pt'\n",
    "    \n",
    "    max_length = 30\n",
    "    scale = 30 \n",
    "    margin = 0.5\n",
    "    num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpha-singapore",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:55.552165Z",
     "iopub.status.busy": "2021-05-10T10:03:55.551586Z",
     "iopub.status.idle": "2021-05-10T10:03:55.566125Z",
     "shell.execute_reply": "2021-05-10T10:03:55.565718Z"
    },
    "papermill": {
     "duration": 0.041293,
     "end_time": "2021-05-10T10:03:55.566234",
     "exception": false,
     "start_time": "2021-05-10T10:03:55.524941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SEED = 2021\n",
    "IMAGE_TRESHOLD = 0.33\n",
    "device = torch.device('cuda')\n",
    "\n",
    "CHECK_SUB = False\n",
    "GET_CV = False\n",
    "\n",
    "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(test)>3: GET_CV = False\n",
    "else: print('this submission notebook will compute CV score, but commit notebook will not')\n",
    "\n",
    "\n",
    "################################################# № 1 MODEL & MODEL PATH ####################################################################\n",
    "\n",
    "transformer_model_1 = '../input/sentence-transformer-models/stsb-roberta-base/0_Transformer'\n",
    "TEXT_MODEL_PATH_1 = '../input/best-selftrained-lang-models/roberta-base_best_loss_num_epochs_15_arcface.bin'\n",
    "ROBERTA_THRESHOLD = 0.85\n",
    "\n",
    "################################################# № 2 MODEL & MODEL PATH ####################################################################\n",
    "\n",
    "transformer_model_2 = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "TEXT_MODEL_PATH_2 = '../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "PARAPHRASE_THRESHOLD = 0.85\n",
    "\n",
    "################################################# № 3 MODEL & MODEL PATH ####################################################################\n",
    "\n",
    "transformer_model_3 = '../input/distilbert-base-indonesian'\n",
    "TEXT_MODEL_PATH_3 = '../input/best-selftrained-lang-models/distilbert-base-indonesian_best_loss_num_epochs_15_arcface.bin'\n",
    "DISTILBERT_THRESHOLD = 0.85\n",
    "\n",
    "################################################ Metric Loss and its params #######################################################\n",
    "loss_module = 'arcface' #'softmax'\n",
    "scale = 30.0\n",
    "m = 0.5 \n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name': transformer_model_1,\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "light-batch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:55.613885Z",
     "iopub.status.busy": "2021-05-10T10:03:55.612988Z",
     "iopub.status.idle": "2021-05-10T10:03:55.615939Z",
     "shell.execute_reply": "2021-05-10T10:03:55.615483Z"
    },
    "papermill": {
     "duration": 0.030139,
     "end_time": "2021-05-10T10:03:55.616060",
     "exception": false,
     "start_time": "2021-05-10T10:03:55.585921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "    return df, df_cu, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opening-reserve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:03:55.669519Z",
     "iopub.status.busy": "2021-05-10T10:03:55.668949Z",
     "iopub.status.idle": "2021-05-10T10:04:03.038916Z",
     "shell.execute_reply": "2021-05-10T10:04:03.039471Z"
    },
    "papermill": {
     "duration": 7.404266,
     "end_time": "2021-05-10T10:04:03.039670",
     "exception": false,
     "start_time": "2021-05-10T10:03:55.635404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,df_cu,image_paths = read_dataset()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "characteristic-processor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.118207Z",
     "iopub.status.busy": "2021-05-10T10:04:03.117420Z",
     "iopub.status.idle": "2021-05-10T10:04:03.122751Z",
     "shell.execute_reply": "2021-05-10T10:04:03.122078Z"
    },
    "papermill": {
     "duration": 0.046135,
     "end_time": "2021-05-10T10:04:03.122901",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.076766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liable-savannah",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.206399Z",
     "iopub.status.busy": "2021-05-10T10:04:03.205652Z",
     "iopub.status.idle": "2021-05-10T10:04:03.214742Z",
     "shell.execute_reply": "2021-05-10T10:04:03.213034Z"
    },
    "papermill": {
     "duration": 0.053805,
     "end_time": "2021-05-10T10:04:03.214910",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.161105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-concrete",
   "metadata": {
    "papermill": {
     "duration": 0.036932,
     "end_time": "2021-05-10T10:04:03.287929",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.250997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metric-aquatic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.381288Z",
     "iopub.status.busy": "2021-05-10T10:04:03.380673Z",
     "iopub.status.idle": "2021-05-10T10:04:03.386632Z",
     "shell.execute_reply": "2021-05-10T10:04:03.385105Z"
    },
    "papermill": {
     "duration": 0.061412,
     "end_time": "2021-05-10T10:04:03.386812",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.325400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersect(*args):\n",
    "    return reduce(np.intersect1d, args)\n",
    "\n",
    "def concat(*args):\n",
    "    return np.unique(np.concatenate(args))\n",
    "\n",
    "def higher(f,*args):\n",
    "    res = {}\n",
    "    keys = np.unique(np.concatenate(args))\n",
    "    for k in keys: \n",
    "        res[k] = np.count_nonzero(np.concatenate(args) == k)\n",
    "    output_dict = dict(filter(lambda item: item[1] >= f, res.items()))\n",
    "    \n",
    "    return np.array(list(output_dict.keys()))\n",
    "\n",
    "def count(*args):\n",
    "    res = {}\n",
    "    keys = np.unique(np.concatenate(args))\n",
    "    for k in keys: \n",
    "        res[k] = np.count_nonzero(np.concatenate(args) == k)\n",
    "    return res\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'],row['text_predictions_roberta_base'],row['text_predictions_param'],row['text_predictions_distil_bert_indon']])\n",
    "    return ' '.join( np.unique(x))\n",
    "\n",
    "def higher_row(row):\n",
    "    higher_value = 2\n",
    "    res = {}\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'],row['text_predictions_roberta_base'],row['text_predictions_param'],row['text_predictions_distil_bert_indon']])\n",
    "    keys = np.unique(x)\n",
    "    for k in keys:\n",
    "        res[k] = np.count_nonzero(np.concatenate([row['image_predictions'], row['text_predictions'],row['text_predictions_roberta_base'],row['text_predictions_param'],row['text_predictions_distil_bert_indon']]) == k)\n",
    "    output_dict = dict(filter(lambda item: item[1] >= higher_value, res.items()))\n",
    "    return ' '.join(output_dict.keys())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "durable-terry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.438138Z",
     "iopub.status.busy": "2021-05-10T10:04:03.437331Z",
     "iopub.status.idle": "2021-05-10T10:04:03.441671Z",
     "shell.execute_reply": "2021-05-10T10:04:03.441144Z"
    },
    "papermill": {
     "duration": 0.032761,
     "end_time": "2021-05-10T10:04:03.441846",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.409085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_predictions(df, embeddings,threshold = 0.0):\n",
    "    \n",
    "    if len(df) > 3:\n",
    "        KNN = 50\n",
    "    else : \n",
    "        KNN = 3\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    predictions = []\n",
    "    for k in tqdm(range(embeddings.shape[0])):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = df['posting_id'].iloc[ids].values\n",
    "        predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contemporary-wisconsin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.487350Z",
     "iopub.status.busy": "2021-05-10T10:04:03.486836Z",
     "iopub.status.idle": "2021-05-10T10:04:03.490551Z",
     "shell.execute_reply": "2021-05-10T10:04:03.490150Z"
    },
    "papermill": {
     "duration": 0.02822,
     "end_time": "2021-05-10T10:04:03.490711",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.462491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size,CFG.img_size,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immediate-warning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.538072Z",
     "iopub.status.busy": "2021-05-10T10:04:03.536364Z",
     "iopub.status.idle": "2021-05-10T10:04:03.538795Z",
     "shell.execute_reply": "2021-05-10T10:04:03.539189Z"
    },
    "papermill": {
     "duration": 0.028518,
     "end_time": "2021-05-10T10:04:03.539317",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.510799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def fetch_loss():\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "social-conversation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.588801Z",
     "iopub.status.busy": "2021-05-10T10:04:03.588171Z",
     "iopub.status.idle": "2021-05-10T10:04:03.592079Z",
     "shell.execute_reply": "2021-05-10T10:04:03.591651Z"
    },
    "papermill": {
     "duration": 0.03318,
     "end_time": "2021-05-10T10:04:03.592179",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.558999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeTextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text,\n",
    "                         return_attention_mask=False,\n",
    "                         return_token_type_ids=False,\n",
    "                         padding='max_length',\n",
    "                         truncation=True,\n",
    "                         max_length=64)\n",
    "        \n",
    "        input_ids = text['input_ids']\n",
    "        \n",
    "        input_ids,labels = self.prepare_mlm_input_and_labels(np.array(input_ids))\n",
    "\n",
    "        input_ids = torch.tensor(input_ids,dtype=torch.long)\n",
    "        labels = torch.tensor(labels,dtype=torch.long)\n",
    "    \n",
    "        return input_ids,labels\n",
    "    \n",
    "    def prepare_mlm_input_and_labels(self,X):\n",
    "        # 15% BERT masking\n",
    "        inp_mask = np.random.rand(*X.shape)<0.15 \n",
    "        # do not mask special tokens\n",
    "        inp_mask[X<=2] = False\n",
    "        # set targets to -1 by default, it means ignore\n",
    "        labels = -100 * np.ones(X.shape, dtype=int)\n",
    "        # set labels for masked tokens\n",
    "        labels[inp_mask] = X[inp_mask]\n",
    "        \n",
    "        # prepare input\n",
    "        X_mlm = np.copy(X)\n",
    "        # set input to [MASK] which is the last token for the 90% of tokens\n",
    "        # this means leaving 10% unchanged\n",
    "        inp_mask_2mask = inp_mask  & (np.random.rand(*X.shape)<0.90)\n",
    "        X_mlm[inp_mask_2mask] = mask_tok\n",
    "\n",
    "        # set 10% to a random token\n",
    "        inp_mask_2random = inp_mask_2mask  & (np.random.rand(*X.shape) < 1/9)\n",
    "        X_mlm[inp_mask_2random] = np.random.randint(3, CONFIG.vocab_size, inp_mask_2random.sum())\n",
    "\n",
    "        return X_mlm, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informative-dancing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.638390Z",
     "iopub.status.busy": "2021-05-10T10:04:03.637293Z",
     "iopub.status.idle": "2021-05-10T10:04:03.640305Z",
     "shell.execute_reply": "2021-05-10T10:04:03.639826Z"
    },
    "papermill": {
     "duration": 0.028457,
     "end_time": "2021-05-10T10:04:03.640403",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.611946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDatasetText(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]  \n",
    "        \n",
    "        return input_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fluid-essex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.686056Z",
     "iopub.status.busy": "2021-05-10T10:04:03.685400Z",
     "iopub.status.idle": "2021-05-10T10:04:03.689007Z",
     "shell.execute_reply": "2021-05-10T10:04:03.688575Z"
    },
    "papermill": {
     "duration": 0.028849,
     "end_time": "2021-05-10T10:04:03.689107",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.660258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "    \n",
    "        return image,torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fiscal-tribute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.740459Z",
     "iopub.status.busy": "2021-05-10T10:04:03.739751Z",
     "iopub.status.idle": "2021-05-10T10:04:03.742576Z",
     "shell.execute_reply": "2021-05-10T10:04:03.742145Z"
    },
    "papermill": {
     "duration": 0.032756,
     "end_time": "2021-05-10T10:04:03.742694",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.709938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNet, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        return F.normalize(feature)\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "digital-multimedia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.798139Z",
     "iopub.status.busy": "2021-05-10T10:04:03.797188Z",
     "iopub.status.idle": "2021-05-10T10:04:03.800060Z",
     "shell.execute_reply": "2021-05-10T10:04:03.799638Z"
    },
    "papermill": {
     "duration": 0.03734,
     "end_time": "2021-05-10T10:04:03.800160",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.762820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbours_cos_sim(df,embeddings,THRESHOLD):\n",
    "    '''\n",
    "    When using cos_sim use normalized features else use normal features\n",
    "    '''\n",
    "    embeddings = cupy.array(embeddings)\n",
    "    \n",
    "    if GET_CV:\n",
    "        thresholds = list(np.arange(0.65,0.95,0.05))\n",
    "\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            \n",
    "################################################# Code for Getting Preds #########################################\n",
    "            preds = []\n",
    "            CHUNK = 1024*4\n",
    "\n",
    "            print('Finding similar titles...for threshold :',threshold)\n",
    "            CTS = len(embeddings)//CHUNK\n",
    "            if len(embeddings)%CHUNK!=0: CTS += 1\n",
    "\n",
    "            for j in range( CTS ):\n",
    "                a = j*CHUNK\n",
    "                b = (j+1)*CHUNK\n",
    "                b = min(b,len(embeddings))\n",
    "\n",
    "                cts = cupy.matmul(embeddings,embeddings[a:b].T).T\n",
    "\n",
    "                for k in range(b-a):\n",
    "                    IDX = cupy.where(cts[k,]>threshold)[0]\n",
    "                    o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "                    o = ' '.join(o)\n",
    "                    preds.append(o)\n",
    "######################################################################################################################\n",
    "            df['pred_matches'] = preds\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "            \n",
    "    else:\n",
    "        preds = []\n",
    "        CHUNK = 1024*4\n",
    "        threshold = THRESHOLD\n",
    "\n",
    "        print('Finding similar texts...for threshold :',threshold)\n",
    "        CTS = len(embeddings)//CHUNK\n",
    "        if len(embeddings)%CHUNK!=0: CTS += 1\n",
    "\n",
    "        for j in range( CTS ):\n",
    "            a = j*CHUNK\n",
    "            b = (j+1)*CHUNK\n",
    "            b = min(b,len(embeddings))\n",
    "            print('chunk',a,'to',b)\n",
    "\n",
    "            cts = cupy.matmul(embeddings,embeddings[a:b].T).T\n",
    "\n",
    "            for k in range(b-a):\n",
    "                IDX = cupy.where(cts[k,]>threshold)[0]\n",
    "                o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "                preds.append(o)\n",
    "                    \n",
    "    return df, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "electric-document",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.866123Z",
     "iopub.status.busy": "2021-05-10T10:04:03.845188Z",
     "iopub.status.idle": "2021-05-10T10:04:03.877212Z",
     "shell.execute_reply": "2021-05-10T10:04:03.877641Z"
    },
    "papermill": {
     "duration": 0.056474,
     "end_time": "2021-05-10T10:04:03.877786",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.821312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "credit : https://github.com/HuangYG123/CurricularFace/blob/8b2f47318117995aa05490c05b455b113489917e/head/metrics.py#L70\n",
    "'''\n",
    "\n",
    "def l2_norm(input, axis = 1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "\n",
    "    return output\n",
    "\n",
    "class CurricularFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s = 30, m = 0.50):\n",
    "        super(CurricularFace, self).__init__()\n",
    "\n",
    "        print('Using Curricular Face')\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        self.kernel = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.register_buffer('t', torch.zeros(1))\n",
    "        nn.init.normal_(self.kernel, std=0.01)\n",
    "\n",
    "    def forward(self, embbedings, label):\n",
    "        embbedings = l2_norm(embbedings, axis = 1)\n",
    "        kernel_norm = l2_norm(self.kernel, axis = 0)\n",
    "        cos_theta = torch.mm(embbedings, kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "        with torch.no_grad():\n",
    "            origin_cos = cos_theta.clone()\n",
    "        target_logit = cos_theta[torch.arange(0, embbedings.size(0)), label].view(-1, 1)\n",
    "\n",
    "        sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n",
    "        cos_theta_m = target_logit * self.cos_m - sin_theta * self.sin_m #cos(target+margin)\n",
    "        mask = cos_theta > cos_theta_m\n",
    "        final_target_logit = torch.where(target_logit > self.threshold, cos_theta_m, target_logit - self.mm)\n",
    "\n",
    "        hard_example = cos_theta[mask]\n",
    "        with torch.no_grad():\n",
    "            self.t = target_logit.mean() * 0.01 + (1 - 0.01) * self.t\n",
    "        cos_theta[mask] = hard_example * (self.t + hard_example)\n",
    "        cos_theta.scatter_(1, label.view(-1, 1).long(), final_target_logit)\n",
    "        output = cos_theta * self.s\n",
    "        return output, nn.CrossEntropyLoss()(output,label)\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output\n",
    "\n",
    "class ShopeeModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, model_name,\n",
    "        n_classes = CFG.classes,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        if model_name == \"curricular_face_eca_nfnet_l1\":\n",
    "            self.backbone = timm.create_model(\"eca_nfnet_l1\", pretrained=pretrained)\n",
    "        else:\n",
    "            self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif \"nfnet\" in model_name:\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "            \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "        \n",
    "        if model_name == \"curricular_face_eca_nfnet_l1\":\n",
    "            self.final = CurricularFace(final_in_features, \n",
    "                                   n_classes, \n",
    "                                   s=scale, \n",
    "                                   m=margin)\n",
    "        else:\n",
    "            self.final = ArcMarginProduct(\n",
    "                final_in_features,\n",
    "                n_classes,\n",
    "                scale = scale,\n",
    "                margin = margin,\n",
    "                easy_margin = False,\n",
    "                ls_eps = 0.0\n",
    "            )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broke-custom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.929096Z",
     "iopub.status.busy": "2021-05-10T10:04:03.928352Z",
     "iopub.status.idle": "2021-05-10T10:04:03.930723Z",
     "shell.execute_reply": "2021-05-10T10:04:03.931188Z"
    },
    "papermill": {
     "duration": 0.032892,
     "end_time": "2021-05-10T10:04:03.931308",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.898416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    \"\"\"from: https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        \n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)\n",
    "\n",
    "\n",
    "def replace_activations(model, existing_layer, new_layer):\n",
    "    \n",
    "    \"\"\"A function for replacing existing activation layers\"\"\"\n",
    "    \n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "billion-tonight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:03.981330Z",
     "iopub.status.busy": "2021-05-10T10:04:03.980536Z",
     "iopub.status.idle": "2021-05-10T10:04:03.983217Z",
     "shell.execute_reply": "2021-05-10T10:04:03.982794Z"
    },
    "papermill": {
     "duration": 0.031383,
     "end_time": "2021-05-10T10:04:03.983319",
     "exception": false,
     "start_time": "2021-05-10T10:04:03.951936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths, model_name, model_path, is_mish = False):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeModel(model_name=model_name)\n",
    "    model.eval()\n",
    "    \n",
    "    if is_mish:\n",
    "        model = replace_activations(model, torch.nn.SiLU, Mish())    \n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sexual-aberdeen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:04.037375Z",
     "iopub.status.busy": "2021-05-10T10:04:04.036774Z",
     "iopub.status.idle": "2021-05-10T10:04:04.040379Z",
     "shell.execute_reply": "2021-05-10T10:04:04.039732Z"
    },
    "papermill": {
     "duration": 0.036351,
     "end_time": "2021-05-10T10:04:04.040506",
     "exception": false,
     "start_time": "2021-05-10T10:04:04.004155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeNetExtend(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 pooling='mean_pooling',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 loss_module='softmax',\n",
    "                 scale=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNetExtend, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.pooling = pooling\n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes,\n",
    "                                          scale=scale, margin=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask, label):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        if self.loss_module == 'arcface':\n",
    "            logits = self.final(feature, label)\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "            features = self.relu(features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "guided-kentucky",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:04.090553Z",
     "iopub.status.busy": "2021-05-10T10:04:04.090048Z",
     "iopub.status.idle": "2021-05-10T10:04:04.094010Z",
     "shell.execute_reply": "2021-05-10T10:04:04.093584Z"
    },
    "papermill": {
     "duration": 0.032942,
     "end_time": "2021-05-10T10:04:04.094117",
     "exception": false,
     "start_time": "2021-05-10T10:04:04.061175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embeddings(df,model_params, transformer_model_path, ext = False):\n",
    "    embeds = []\n",
    "    if ext :\n",
    "        model = ShopeeNetExtend(**model_params)\n",
    "    else:\n",
    "        model = ShopeeNet(**model_params)\n",
    "    model.eval()\n",
    "    \n",
    "    model.load_state_dict(dict(list(torch.load(transformer_model_path).items())[:-1]))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # change datasets for different Models\n",
    "    text_dataset = ShopeeDatasetText(df)\n",
    "    text_loader = torch.utils.data.DataLoader(\n",
    "        text_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask in tqdm(text_loader): \n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            feat = model(input_ids, attention_mask)\n",
    "            text_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(text_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "early-latitude",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:04.143174Z",
     "iopub.status.busy": "2021-05-10T10:04:04.142520Z",
     "iopub.status.idle": "2021-05-10T10:04:04.146050Z",
     "shell.execute_reply": "2021-05-10T10:04:04.145639Z"
    },
    "papermill": {
     "duration": 0.03135,
     "end_time": "2021-05-10T10:04:04.146149",
     "exception": false,
     "start_time": "2021-05-10T10:04:04.114799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, max_features = 25_000):\n",
    "    \n",
    "    model = TfidfVectorizer( binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    preds = []\n",
    "    CHUNK = 1024*4\n",
    "\n",
    "    print('Finding similar titles...')\n",
    "    CTS = len(df)//CHUNK\n",
    "    if len(df)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(df))\n",
    "        print('chunk',a,'to',b)\n",
    "\n",
    "        # COSINE SIMILARITY DISTANCE\n",
    "        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]> 0.75)[0]\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "    \n",
    "    del model,text_embeddings\n",
    "    gc.collect()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-nightlife",
   "metadata": {
    "papermill": {
     "duration": 0.020849,
     "end_time": "2021-05-10T10:04:04.187861",
     "exception": false,
     "start_time": "2021-05-10T10:04:04.167012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMAGE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "located-operation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:04.235022Z",
     "iopub.status.busy": "2021-05-10T10:04:04.234428Z",
     "iopub.status.idle": "2021-05-10T10:04:18.930767Z",
     "shell.execute_reply": "2021-05-10T10:04:18.931311Z"
    },
    "papermill": {
     "duration": 14.722782,
     "end_time": "2021-05-10T10:04:18.931509",
     "exception": false,
     "start_time": "2021-05-10T10:04:04.208727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for eca_nfnet_l1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 512)\n",
      "Building Model Backbone for efficientnet_b3 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 512)\n",
      "Building Model Backbone for tf_efficientnet_b5_ns model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 512)\n",
      "Building Model Backbone for eca_nfnet_l0 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3604.39it/s]\n"
     ]
    }
   ],
   "source": [
    "image_embeddings1 = get_image_embeddings(image_paths.values, CFG.model_name1, CFG.model_path1, True)\n",
    "image_embeddings2 = get_image_embeddings(image_paths.values, CFG.model_name2, CFG.model_path2, False)\n",
    "image_embeddings3 = get_image_embeddings(image_paths.values, CFG.model_name3, CFG.model_path3, False)\n",
    "image_embeddings4 = get_image_embeddings(image_paths.values, CFG.model_name4, CFG.model_path4, True)\n",
    "#image_embeddings5 = get_image_embeddings(image_paths.values, CFG.model_name5, CFG.model_path5, True)\n",
    "\n",
    "image_embeddings = (image_embeddings1 + image_embeddings2 + image_embeddings3 + image_embeddings4 ) / 4\n",
    "image_predictions = get_image_predictions(df, image_embeddings, threshold = IMAGE_TRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-future",
   "metadata": {
    "papermill": {
     "duration": 0.027524,
     "end_time": "2021-05-10T10:04:18.987515",
     "exception": false,
     "start_time": "2021-05-10T10:04:18.959991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TEXT INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "single-collapse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:04:19.050539Z",
     "iopub.status.busy": "2021-05-10T10:04:19.049827Z",
     "iopub.status.idle": "2021-05-10T10:05:40.683383Z",
     "shell.execute_reply": "2021-05-10T10:05:40.683813Z"
    },
    "papermill": {
     "duration": 81.668832,
     "end_time": "2021-05-10T10:05:40.683972",
     "exception": false,
     "start_time": "2021-05-10T10:04:19.015140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n",
      "Finding similar texts...for threshold : 0.85\n",
      "chunk 0 to 3\n",
      "Finding similar texts...for threshold : 0.85\n",
      "chunk 0 to 3\n",
      "Finding similar texts...for threshold : 0.85\n",
      "chunk 0 to 3\n",
      "Finding similar titles...\n",
      "chunk 0 to 3\n"
     ]
    }
   ],
   "source": [
    "# ROBERTA base\n",
    "\n",
    "model_params['model_name'] = transformer_model_1\n",
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model_1)\n",
    "CONFIG = transformers.AutoConfig.from_pretrained(transformer_model_1)\n",
    "mask_tok = 250001\n",
    "text_embeddings_roberta_base = get_text_embeddings(df, model_params,TEXT_MODEL_PATH_1)\n",
    "\n",
    "# THIS WORKING \n",
    "# sentence-transformers/paraphrase-xlm-r-multilingual-v1\n",
    "model_params['model_name'] = transformer_model_2\n",
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model_2)\n",
    "CONFIG = transformers.AutoConfig.from_pretrained(transformer_model_2)\n",
    "mask_tok = 250001\n",
    "text_embeddings_param = get_text_embeddings(df, model_params,TEXT_MODEL_PATH_2)\n",
    "\n",
    "model_params['model_name'] = transformer_model_3\n",
    "TOKENIZER = DistilBertTokenizer.from_pretrained(transformer_model_3)\n",
    "DistilBertModel.from_pretrained(transformer_model_3)\n",
    "CONFIG = transformers.AutoConfig.from_pretrained(transformer_model_3)\n",
    "mask_tok = 31999\n",
    "text_embeddings_distil_bert_indonesian = get_text_embeddings(df, model_params,TEXT_MODEL_PATH_3)\n",
    "\n",
    "#roberta base predictions\n",
    "df,text_predictions_roberta_base = get_neighbours_cos_sim(df,text_embeddings_roberta_base, ROBERTA_THRESHOLD)\n",
    "\n",
    "#param-sentece predictions\n",
    "df,text_predictions_param = get_neighbours_cos_sim(df,text_embeddings_param,PARAPHRASE_THRESHOLD)\n",
    "\n",
    "#disitl indonesian predictions\n",
    "df,text_predictions_distil_bert_indon = get_neighbours_cos_sim(df,text_embeddings_distil_bert_indonesian,DISTILBERT_THRESHOLD)\n",
    "\n",
    "#text_embeddings = (text_embeddings_param + text_embeddings_distil_bert_indonesian + text_embeddings_roberta_base) / 3\n",
    "#df,text_predictions_sbert = get_neighbours_cos_sim(df,text_embeddings)\n",
    "\n",
    "text_predictions_tfidf = get_text_predictions(df, max_features = 25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "productive-bernard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:05:40.756853Z",
     "iopub.status.busy": "2021-05-10T10:05:40.756169Z",
     "iopub.status.idle": "2021-05-10T10:05:40.759024Z",
     "shell.execute_reply": "2021-05-10T10:05:40.758487Z"
    },
    "papermill": {
     "duration": 0.04208,
     "end_time": "2021-05-10T10:05:40.759129",
     "exception": false,
     "start_time": "2021-05-10T10:05:40.717049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GET_CV:\n",
    "    print('text_predictions_roberta_base:\\n', text_predictions_roberta_base,\"\\n\",\"==\"*40)\n",
    "    print('text_predictions_param:\\n', text_predictions_param,\"\\n\",\"==\"*10)\n",
    "    print('text_predictions_distil_bert_indon:\\n', text_predictions_distil_bert_indon,\"\\n\",\"==\"*40)\n",
    "    print('image_predictions:\\n', image_predictions,\"\\n\",\"==\"*40)\n",
    "    print('text_predictions:\\n', text_predictions_tfidf,\"\\n\",\"==\"*40)\n",
    "    print(\"Higher 1:\\n\",higher(1,text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))\n",
    "    print(\"Higher 2:\\n\",higher(2,text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))\n",
    "    print(\"Higher 3:\\n\",higher(3,text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))\n",
    "    print(\"Higher 4:\\n\",higher(4,text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))\n",
    "    print(\"Intersec:\\n\",intersect(text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))\n",
    "    print(\"Count:\\n\",count(text_predictions_roberta_base,text_predictions_param,text_predictions_distil_bert_indon,image_predictions,text_predictions_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "under-barrier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:05:40.835850Z",
     "iopub.status.busy": "2021-05-10T10:05:40.835124Z",
     "iopub.status.idle": "2021-05-10T10:05:40.972381Z",
     "shell.execute_reply": "2021-05-10T10:05:40.971920Z"
    },
    "papermill": {
     "duration": 0.181685,
     "end_time": "2021-05-10T10:05:40.972504",
     "exception": false,
     "start_time": "2021-05-10T10:05:40.790819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not GET_CV:\n",
    "    df['text_predictions_roberta_base'] = text_predictions_roberta_base\n",
    "    df['text_predictions_param'] = text_predictions_param\n",
    "    df['text_predictions_distil_bert_indon'] = text_predictions_distil_bert_indon\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions'] = text_predictions_tfidf\n",
    "    df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "#    df['matches'] = df.apply(higher_row, axis=1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    df['text_predictions_roberta_base'] = text_predictions_roberta_base\n",
    "    df['text_predictions_param'] = text_predictions_param\n",
    "    df['text_predictions_distil_bert_indon'] = text_predictions_distil_bert_indon\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions'] = text_predictions_tfidf\n",
    "    df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "#    df['matches'] = df.apply(higher_row, axis=1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.059292,
   "end_time": "2021-05-10T10:05:43.738214",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-10T10:03:40.678922",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
