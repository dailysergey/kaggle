{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014247,
     "end_time": "2021-05-06T20:44:18.443160",
     "exception": false,
     "start_time": "2021-05-06T20:44:18.428913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this Notebook\n",
    "\n",
    "After carefull considerations and doing a lot of experiments with tfidf and Bert-Based models , I strongly feel Bert-based models might do better if trained and used in the right way. [This](https://www.kaggle.com/c/shopee-product-matching/discussion/231510) dicussion thread talks about the usage of different approaches for text and discusses why BERT-base model might be better.\n",
    "\n",
    "I started with normal Hugging Face BERT type models , but I found Sentence transformers pre-trained models a better idea . As sentence transformer models were already trained in a siamese fashion especially for information retreival and semantic similarity tasks it's much better idea to start with them and then fine-tune it on our data. I have used <b> paraphrase-xlm-r-multilingual-v1 </b> from sentence transformers , one can try with other very good models also . I have uploaded all models for offline use [here](https://www.kaggle.com/tanulsingh077/sentence-transformer-models)\n",
    "\n",
    "One more additional thing which has come as a result of experimentation is to train with full data instead of splitting and then saving models on eval set. To avoid overfitting one can use strong regularizers like using fully connected layer on top of bert output , weight decay,etc\n",
    "\n",
    "This is the training notebook , you can find the inference notebook [here](https://www.kaggle.com/tanulsingh077/reaching-0-612-with-text-only-shopee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:18.477531Z",
     "iopub.status.busy": "2021-05-06T20:44:18.476727Z",
     "iopub.status.idle": "2021-05-06T20:44:23.895412Z",
     "shell.execute_reply": "2021-05-06T20:44:23.894065Z"
    },
    "papermill": {
     "duration": 5.44007,
     "end_time": "2021-05-06T20:44:23.895620",
     "exception": false,
     "start_time": "2021-05-06T20:44:18.455550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visuals and CV2\n",
    "import cv2\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n",
    "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from transformers import (BertTokenizer, BertModel,DistilBertTokenizer, DistilBertModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013005,
     "end_time": "2021-05-06T20:44:23.922010",
     "exception": false,
     "start_time": "2021-05-06T20:44:23.909005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:23.958991Z",
     "iopub.status.busy": "2021-05-06T20:44:23.958237Z",
     "iopub.status.idle": "2021-05-06T20:44:31.618154Z",
     "shell.execute_reply": "2021-05-06T20:44:31.616493Z"
    },
    "papermill": {
     "duration": 7.683111,
     "end_time": "2021-05-06T20:44:31.618329",
     "exception": false,
     "start_time": "2021-05-06T20:44:23.935218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "SEED = 2021\n",
    "LR = 5e-5\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "################################################# MODEL ####################################################################\n",
    "model_name='distilbert-base-indonesian'\n",
    "transformer_model = '../input/distilbert-base-indonesian'\n",
    "\n",
    "TOKENIZER = DistilBertTokenizer.from_pretrained(transformer_model)\n",
    "DistilBertModel.from_pretrained(transformer_model)\n",
    "CONFIG = transformers.AutoConfig.from_pretrained(transformer_model)\n",
    "mask_tok = 31999\n",
    "\n",
    "################################################ Metric Loss and its params #######################################################\n",
    "loss_module = 'arcface'#'softmax'\n",
    "s = 30.0\n",
    "m = 0.5 \n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "############################################################################################################################\n",
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name':transformer_model,\n",
    "    'pooling':'clf',\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0,\n",
    "    'loss_module':loss_module,\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012662,
     "end_time": "2021-05-06T20:44:31.644008",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.631346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.683296Z",
     "iopub.status.busy": "2021-05-06T20:44:31.681390Z",
     "iopub.status.idle": "2021-05-06T20:44:31.684014Z",
     "shell.execute_reply": "2021-05-06T20:44:31.684540Z"
    },
    "papermill": {
     "duration": 0.024373,
     "end_time": "2021-05-06T20:44:31.684720",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.660347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.716218Z",
     "iopub.status.busy": "2021-05-06T20:44:31.715381Z",
     "iopub.status.idle": "2021-05-06T20:44:31.719629Z",
     "shell.execute_reply": "2021-05-06T20:44:31.719086Z"
    },
    "papermill": {
     "duration": 0.021987,
     "end_time": "2021-05-06T20:44:31.719782",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.697795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_loss():\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013098,
     "end_time": "2021-05-06T20:44:31.746217",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.733119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.784043Z",
     "iopub.status.busy": "2021-05-06T20:44:31.782033Z",
     "iopub.status.idle": "2021-05-06T20:44:31.784751Z",
     "shell.execute_reply": "2021-05-06T20:44:31.785329Z"
    },
    "papermill": {
     "duration": 0.025507,
     "end_time": "2021-05-06T20:44:31.785487",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.759980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]  \n",
    "        \n",
    "        return input_ids, attention_mask, torch.tensor(row.label_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013159,
     "end_time": "2021-05-06T20:44:31.811924",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.798765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric Learning Losses\n",
    "\n",
    "https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.854919Z",
     "iopub.status.busy": "2021-05-06T20:44:31.854004Z",
     "iopub.status.idle": "2021-05-06T20:44:31.858884Z",
     "shell.execute_reply": "2021-05-06T20:44:31.858299Z"
    },
    "papermill": {
     "duration": 0.0338,
     "end_time": "2021-05-06T20:44:31.859048",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.825248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012838,
     "end_time": "2021-05-06T20:44:31.885610",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.872772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.928604Z",
     "iopub.status.busy": "2021-05-06T20:44:31.927617Z",
     "iopub.status.idle": "2021-05-06T20:44:31.931424Z",
     "shell.execute_reply": "2021-05-06T20:44:31.930850Z"
    },
    "papermill": {
     "duration": 0.032491,
     "end_time": "2021-05-06T20:44:31.931564",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.899073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 pooling='mean_pooling',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 loss_module='softmax',\n",
    "                 s=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNet, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(transformer_model)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.pooling = pooling\n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes,\n",
    "                                          s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask, label):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        if self.loss_module == 'arcface':\n",
    "            logits = self.final(feature, label)\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "            features = self.relu(features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013473,
     "end_time": "2021-05-06T20:44:31.958892",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.945419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:31.996359Z",
     "iopub.status.busy": "2021-05-06T20:44:31.995277Z",
     "iopub.status.idle": "2021-05-06T20:44:31.998742Z",
     "shell.execute_reply": "2021-05-06T20:44:31.998182Z"
    },
    "papermill": {
     "duration": 0.026663,
     "end_time": "2021-05-06T20:44:31.998927",
     "exception": false,
     "start_time": "2021-05-06T20:44:31.972264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader,model,criterion,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    loss_score = AverageMeter()\n",
    "    \n",
    "    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for bi,d in tk0:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "        input_ids = d[0]\n",
    "        attention_mask = d[1]\n",
    "        targets = d[2]\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids,attention_mask,targets)\n",
    "        \n",
    "        loss = criterion(output,targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_score.update(loss.detach().item(), batch_size)\n",
    "        tk0.set_postfix(Train_Loss=loss_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01346,
     "end_time": "2021-05-06T20:44:32.026391",
     "exception": false,
     "start_time": "2021-05-06T20:44:32.012931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:32.062203Z",
     "iopub.status.busy": "2021-05-06T20:44:32.061534Z",
     "iopub.status.idle": "2021-05-06T20:44:32.314710Z",
     "shell.execute_reply": "2021-05-06T20:44:32.313577Z"
    },
    "papermill": {
     "duration": 0.274621,
     "end_time": "2021-05-06T20:44:32.314904",
     "exception": false,
     "start_time": "2021-05-06T20:44:32.040283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "data['filepath'] = data['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/', 'train_images', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:32.349401Z",
     "iopub.status.busy": "2021-05-06T20:44:32.348310Z",
     "iopub.status.idle": "2021-05-06T20:44:32.360376Z",
     "shell.execute_reply": "2021-05-06T20:44:32.359786Z"
    },
    "papermill": {
     "duration": 0.031113,
     "end_time": "2021-05-06T20:44:32.360537",
     "exception": false,
     "start_time": "2021-05-06T20:44:32.329424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "data['label_group'] = encoder.fit_transform(data['label_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:32.403296Z",
     "iopub.status.busy": "2021-05-06T20:44:32.400697Z",
     "iopub.status.idle": "2021-05-06T20:44:32.404028Z",
     "shell.execute_reply": "2021-05-06T20:44:32.404568Z"
    },
    "papermill": {
     "duration": 0.030212,
     "end_time": "2021-05-06T20:44:32.404763",
     "exception": false,
     "start_time": "2021-05-06T20:44:32.374551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Defining DataSet\n",
    "    train_dataset = ShopeeDataset(\n",
    "        csv=data\n",
    "    )\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    # Defining Device\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Defining Model for specific fold\n",
    "    model = ShopeeNet(**model_params)\n",
    "    model.to(device)\n",
    "    \n",
    "    #DEfining criterion\n",
    "    criterion = fetch_loss()\n",
    "    criterion.to(device)\n",
    "        \n",
    "    # Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "            ]  \n",
    "    \n",
    "    optimizer = AdamW(optimizer_parameters, lr=LR)\n",
    "    \n",
    "    #Defining LR SCheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=len(train_loader)*2, \n",
    "        num_training_steps=len(train_loader)*EPOCHS\n",
    "    )\n",
    "        \n",
    "    # THE ENGINE LOOP\n",
    "    best_loss = 10000\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_fn(train_loader, model,criterion, optimizer, device,scheduler=scheduler,epoch=epoch)\n",
    "        \n",
    "        if train_loss.avg < best_loss:\n",
    "            best_loss = train_loss.avg\n",
    "            torch.save(model.state_dict(),f'{model_name}_best_loss_num_epochs_{EPOCHS}_{loss_module}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:44:32.439238Z",
     "iopub.status.busy": "2021-05-06T20:44:32.438337Z",
     "iopub.status.idle": "2021-05-06T21:20:19.114320Z",
     "shell.execute_reply": "2021-05-06T21:20:19.115087Z"
    },
    "papermill": {
     "duration": 2146.69597,
     "end_time": "2021-05-06T21:20:19.115352",
     "exception": false,
     "start_time": "2021-05-06T20:44:32.419382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1070/1070 [02:18<00:00,  7.73it/s, Epoch=0, LR=2.5e-5, Train_Loss=23.8]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.63it/s, Epoch=1, LR=5e-5, Train_Loss=20.8]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.61it/s, Epoch=2, LR=4.62e-5, Train_Loss=17.2]\n",
      "100%|██████████| 1070/1070 [02:22<00:00,  7.53it/s, Epoch=3, LR=4.23e-5, Train_Loss=14.1]\n",
      "100%|██████████| 1070/1070 [02:21<00:00,  7.54it/s, Epoch=4, LR=3.85e-5, Train_Loss=11.7]\n",
      "100%|██████████| 1070/1070 [02:21<00:00,  7.56it/s, Epoch=5, LR=3.46e-5, Train_Loss=9.88]\n",
      "100%|██████████| 1070/1070 [02:21<00:00,  7.54it/s, Epoch=6, LR=3.08e-5, Train_Loss=8.36]\n",
      "100%|██████████| 1070/1070 [02:21<00:00,  7.58it/s, Epoch=7, LR=2.69e-5, Train_Loss=7.12]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.60it/s, Epoch=8, LR=2.31e-5, Train_Loss=6.11]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.63it/s, Epoch=9, LR=1.92e-5, Train_Loss=5.27]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.63it/s, Epoch=10, LR=1.54e-5, Train_Loss=4.61]\n",
      "100%|██████████| 1070/1070 [02:20<00:00,  7.62it/s, Epoch=11, LR=1.15e-5, Train_Loss=4.09]\n",
      "100%|██████████| 1070/1070 [02:21<00:00,  7.56it/s, Epoch=12, LR=7.7e-6, Train_Loss=3.7]\n",
      "100%|██████████| 1070/1070 [02:22<00:00,  7.52it/s, Epoch=13, LR=3.85e-6, Train_Loss=3.43]\n",
      "100%|██████████| 1070/1070 [02:22<00:00,  7.51it/s, Epoch=14, LR=3.59e-9, Train_Loss=3.28]\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2181.316328,
   "end_time": "2021-05-06T21:20:33.549813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-06T20:44:12.233485",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
